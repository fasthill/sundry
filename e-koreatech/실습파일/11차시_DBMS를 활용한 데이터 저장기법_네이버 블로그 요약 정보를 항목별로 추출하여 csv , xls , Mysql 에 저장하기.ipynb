{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      " 네이버 블로그 정보 수집하 xlsx, csv 형식으로 저장하고 MySQL DB에 저장하기\n",
      "====================================================================================================\n",
      "1.크롤링할 키워드는 무엇입니까?: 서진수 빅데이터\n",
      "2.수집할 데이터는 몇 건입니까?: 10\n",
      "3.파일을 저장할 폴더명만 쓰세요(기본값:c:/py_temp/):\n",
      "====================================================================================================\n",
      "2 페이지 정보를 추출하고 있으니 잠시만 기다려 주세요~~^^\n",
      "3 페이지 정보를 추출하고 있으니 잠시만 기다려 주세요~~^^\n",
      "1번째 게시글의 이미지 저장을 완료했습니다\n",
      "\n",
      "1.번호: 1\n",
      "2.제목: 전문가에게 길을 묻다. 빅데이터 전문가편 서진수 대표\n",
      "3.요약내용: 빅데이터 전문가편을 진행하였습니다. 각종 티비 프로그램과 인공지능과 관련된... 등재된 서진수 대표님과 함께 했습니다. 예전에 강연을 잘하셔서 국회의원 상을... \n",
      "4.작성일자: 2022.08.06.\n",
      "5.블로그 닉네임:  뉴턴의과학실&뷰사이언스 \n",
      "\n",
      "\n",
      "2번째 게시글의 이미지 저장을 완료했습니다\n",
      "\n",
      "1.번호: 2\n",
      "2.제목: 마소캠퍼스 빅데이터 분석 오픈 세미나!(서진수 대표님) 151030\n",
      "3.요약내용: 진행한 빅데이터 분석 오픈 세미나 강연 후기입니다 진행은 서진수 대표님이... 하락중인 데이터를 보고 어떤 인사이트를 얻을 수 있는지, 차례 차례 알려주셨습니다... \n",
      "4.작성일자: 2015.10.31.\n",
      "5.블로그 닉네임:  어쩐지 오늘은 \n",
      "\n",
      "\n",
      "3번째 게시글의 이미지 저장을 완료했습니다\n",
      "\n",
      "1.번호: 3\n",
      "2.제목: 빅데이터 전문가 서진수 대표의 트랜드 분석 강의\n",
      "3.요약내용: 빅데이터 전문가 서진수 대표님. 빅데이터 강의는 분야를 막론하고 누구든... 미래 빅데이터를 추출하는 것은 기술적으로 그리 어렵지 않다. 오히려 데이터를 어떻게... \n",
      "4.작성일자: 2017.03.07.\n",
      "5.블로그 닉네임:  카루의 프리랜서 라이프 \n",
      "\n",
      "\n",
      "4번째 게시글의 이미지 저장을 완료했습니다\n",
      "\n",
      "1.번호: 4\n",
      "2.제목: 소셜포럼] 서진수 대표, 변화의 흐름을 이끄는 빅데이터... \n",
      "3.요약내용: 창의와 융합의 신(新) 물결 ‘4차 산업혁명’ 변화의 흐름을 이끄는 빅데이터 전문가 서진수 ㈜컨시어지소프트 대표 | ㈜데이터앤피플 대표 언제부터인가 미디어에서... \n",
      "4.작성일자: 2017.08.24.\n",
      "5.블로그 닉네임:  위클리피플 [명사와의 만남] _신지식인 소셜포럼 \n",
      "\n",
      "\n",
      "5번째 게시글의 이미지 저장을 완료했습니다\n",
      "\n",
      "1.번호: 5\n",
      "2.제목: 방법, 빅데이터 관리가 가장 기본 <(주)컨시어지소프트 서진수... \n",
      "3.요약내용: 된 빅데이터 기술 활용법 알린다” ㈜컨시어지소프트, ㈜데이터앤피플 서진수 대표 4차산업혁명과 인공지능을 실과 바늘의 관계에... \n",
      "4.작성일자: 2017.09.25.\n",
      "5.블로그 닉네임:  월간 인터뷰 (Interview) \n",
      "\n",
      "\n",
      "6번째 게시글의 이미지 저장을 완료했습니다\n",
      "\n",
      "1.번호: 6\n",
      "2.제목: 빅데이터 활용으로 4차산업시대를 준비하자_서진수대표 특강... \n",
      "3.요약내용: 스몰데이터만으로도 충분히 고객관리가 가능합니다. ^^ 그렇게 지난 날의 관심과 열정을 떠올리며, 서진수대표님의 빅데이터 활용 특강을 갔습니다. 아재개그,,,,,를... \n",
      "4.작성일자: 2017.02.28.\n",
      "5.블로그 닉네임:  위드앤교육컨설팅_퍼실리테이션 전문교육 \n",
      "\n",
      "\n",
      "7번째 게시글의 이미지 저장을 완료했습니다\n",
      "\n",
      "1.번호: 7\n",
      "2.제목: 빅데이터 전문가 서진수 강사님의 빅데이터 활용과 4차산업에... \n",
      "3.요약내용: 서진수 강사님의 빅데이터 관련 강의를 들으러 강남을 다녀왔드랬죠!! 빅데이터 전문가라고 하면 사실 카카오다음의 '그 분'을 떠올리실텐데요..ㅋㅋ 서진수 강사님도... \n",
      "4.작성일자: 2017.02.27.\n",
      "5.블로그 닉네임:  한결다온교육연구소 \n",
      "\n",
      "\n",
      "8번째 게시글의 이미지 저장을 완료했습니다\n",
      "\n",
      "1.번호: 8\n",
      "2.제목: 빅데이터 분석, 웹크롤링 강남 아이티윌과 서진수 강사님의 특강\n",
      "3.요약내용: 오늘은 강남 아이티윌과 서진수 강사님의 빅데이터분석을 위한 R의 활용방안과 텍스트 마이닝, 데이터 시각화, 통계 패키지의 활용, 데이터 수집을 위한 크롤링 등의... \n",
      "4.작성일자: 2017.08.08.\n",
      "5.블로그 닉네임:  우수훈련기관 아이티윌 \n",
      "\n",
      "\n",
      "9번째 게시글의 이미지 저장을 완료했습니다\n",
      "\n",
      "1.번호: 9\n",
      "2.제목: [모임소개] KBS \"명견만리\" 서진수 직강 '빅데이터 전문가... \n",
      "3.요약내용: (8) 2018.04.22 윈도우10 포스트잇 Sticky Notes 스티커 메모 (2) 2018.04.13 [모임소개] KBS \"명견만리\" 서진수 직강 '빅데이터 전문가 / 전문강사 양성과정 (0) 2018.... \n",
      "4.작성일자: 2018.04.11.\n",
      "5.블로그 닉네임:  푸우시로의 블로그 \n",
      "\n",
      "\n",
      "10번째 게시글의 이미지 저장을 완료했습니다\n",
      "\n",
      "1.번호: 10\n",
      "2.제목: 서진수 강사님의 빅데이터-R을 활용한 텍스트 마이닝 교육\n",
      "3.요약내용: 서진수 강사님은 빅데이터 전문가로써 방송에도 몇차례 출연하시면서 빅데이터에 관련된 특강을 진행하신 경험도 있으십니다. 데이터베이스와 빅데이터에 관련된... \n",
      "4.작성일자: 2017.07.25.\n",
      "5.블로그 닉네임:  IT취업 나도 할 수 있다. \n",
      "\n",
      "\n",
      "csv 파일 저장 경로: c:\\py_temp\\Naver_View-2022-12-15-12-05-21-서진수 빅데이터\\Naver_View-2022-12-15-12-05-21-서진수 빅데이터.csv\n",
      "xls 파일 저장 경로: c:\\py_temp\\Naver_View-2022-12-15-12-05-21-서진수 빅데이터\\Naver_View-2022-12-15-12-05-21-서진수 빅데이터.xlsx\n"
     ]
    }
   ],
   "source": [
    "#저장할 내용을 목록으로 만들어서 엑셀형식과 csv 형식으로 저장하기\n",
    "\n",
    "#Step 1. 필요한 모듈을 로딩합니다\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup     \n",
    "import pandas as pd   \n",
    "import openpyxl\n",
    "import math\n",
    "import time  \n",
    "import os\n",
    "import urllib.request\n",
    "import urllib\n",
    "\n",
    "#Step 2. 사용자에게 검색 관련 정보들을 입력 받습니다.\n",
    "print(\"=\" *100)\n",
    "print(\" 네이버 블로그 정보 수집하고 xlsx, csv 형식으로 저장하고 MySQL DB에 저장하기\")\n",
    "print(\"=\" *100)\n",
    "\n",
    "query_txt = input('1.크롤링할 키워드는 무엇입니까?: ')\n",
    "cnt=int(input('2.수집할 데이터는 몇 건입니까?: ') )\n",
    "page_cnt = math.ceil(cnt / 60)\n",
    "\n",
    "f_dir = input(\"3.파일을 저장할 폴더명만 쓰세요(기본값:c:/py_temp/):\")\n",
    "if f_dir == '' :\n",
    "    f_dir=\"c:\\\\py_temp\\\\\"\n",
    "    \n",
    "n = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' %(n.tm_year, n.tm_mon, n.tm_mday, n.tm_hour, n.tm_min, n.tm_sec)\n",
    "\n",
    "# Step 3. 크롬 드라이버와 폴더와 파일을 설정하기\n",
    "s1 = Service(\"c:/py_temp/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s1)\n",
    "\n",
    "#이미지를 저장할 디렉토리 생성\n",
    "img_dir = f_dir+'Naver_View'+'-'+s+'-'+query_txt+\"\\\\images\"\n",
    "os.makedirs(img_dir)\n",
    "os.chdir(img_dir)\n",
    "\n",
    "# csv , xlsx 파일명 지정\n",
    "fc_name = f_dir+'Naver_View'+'-'+s+'-'+query_txt+'\\\\'+'Naver_View'+'-'+s+'-'+query_txt+'.csv'\n",
    "fx_name = f_dir+'Naver_View'+'-'+s+'-'+query_txt+'\\\\'+'Naver_View'+'-'+s+'-'+query_txt+'.xlsx'\n",
    "print('=' *100)\n",
    "\n",
    "#Step 4. 네이버에 접속 후 검색하고 블로그 선택하기\n",
    "url = 'https://www.naver.com'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "\n",
    "s_time = time.time( )\n",
    "element = driver.find_element(By.ID,'query')\n",
    "driver.find_element(By.ID,'query').click( )\n",
    "element.send_keys(query_txt)\n",
    "element.send_keys(\"\\n\")\n",
    "time.sleep(2)\n",
    "\n",
    "driver.find_element(By.LINK_TEXT,'VIEW').click( )\n",
    "time.sleep(1)\n",
    "driver.find_element(By.LINK_TEXT,'블로그').click( )\n",
    "\n",
    "# Step 5. 검색 요청 건수만큼 화면 스크롤링 하기\n",
    "# 자동 스크롤다운 함수\n",
    "def scroll_down(driver):\n",
    "    driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight);\")\n",
    "    time.sleep(3)\n",
    "\n",
    "i = 1\n",
    "while (i <= page_cnt+1):\n",
    "    scroll_down(driver) \n",
    "    i += 1\n",
    "    print('%s 페이지 정보를 추출하고 있으니 잠시만 기다려 주세요~~^^' %i)\n",
    "\n",
    "# Step 6. 저장 목록을 만든 후 목록에 있는 내용을 파일에 저장하기\n",
    "\n",
    "no2 = [ ]           # 게시글 번호 컬럼\n",
    "title2 = [ ]        # 게시물 제목 컬럼\n",
    "contents2 = [ ]     # 게시글 내용 컬럼\n",
    "bdate2 = [ ]        # 작성 일자 컬럼\n",
    "nick2 = [ ]         # 블로그 닉네임\n",
    "image2= [ ]         # 이미지 저장 컬럼\n",
    "\n",
    "no = 1       # 게시글 번호용 숫자\n",
    "img_no = 1   # 이미지 번호용 숫자\n",
    "\n",
    "for a in range(1, page_cnt + 1) :\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    blog_list = soup.find('ul','lst_total').find_all('li')\n",
    "        \n",
    "    for i in blog_list:\n",
    "    \n",
    "        #이미지 수집 후 이미지가 있는 게시글만 추가 정보 수집하기\n",
    "        try :\n",
    "            img = i.find('span','thumb_fix').find('img')['src']\n",
    "        except :\n",
    "            continue    \n",
    "        else :\n",
    "            urllib.request.urlretrieve(img,str(img_no)+'.jpg')\n",
    "            print('%s번째 게시글의 이미지 저장을 완료했습니다' %img_no)\n",
    "            print( )        \n",
    "            time.sleep(1)\n",
    "\n",
    "            img_no += 1\n",
    "\n",
    "            # 텍스트 내용 수집\n",
    "            no2.append(no)                            # 게시물 번호 리스트에 추가\n",
    "            print('1.번호:',no)\n",
    "\n",
    "            title_1 = i.find('div','total_area').find_all('a')  \n",
    "            title = title_1[5].get_text()              # 게시물 제목\n",
    "            title2.append(title)                       # 게시물 제목 리스트에 추가\n",
    "            print('2.제목:',title)\n",
    "\n",
    "            contents = i.find('div','api_txt_lines dsc_txt').get_text( )   # 게시물 요약 내용\n",
    "            contents2.append(contents)                # 게시물 내용 리스트에 추가\n",
    "            print('3.요약내용:',contents)\n",
    "\n",
    "            bdate = i.find('span','sub_time sub_txt').get_text( )  # 작성일자\n",
    "            bdate2.append(bdate)                     # 작성일자 리스트에 추가\n",
    "            print('4.작성일자:',bdate)\n",
    "\n",
    "            nick = i.find('span','elss etc_dsc_inner').get_text( )\n",
    "            nick2.append(nick)\n",
    "            print('5.블로그 닉네임:',nick)\n",
    "            \n",
    "            image2.append(' ')\n",
    "\n",
    "            print(\"\\n\")\n",
    "\n",
    "            if no == cnt:\n",
    "                break\n",
    "\n",
    "            no += 1\n",
    "\n",
    "# Step 7.출력 결과를 표(데이터 프레임) 형태로 만들기\n",
    "naver_blog = pd.DataFrame()\n",
    "naver_blog['번호'] = no2\n",
    "naver_blog['제목'] = title2\n",
    "naver_blog['내용'] = contents2\n",
    "naver_blog['작성일자'] = bdate2\n",
    "naver_blog['블로그닉네임'] = nick2\n",
    "\n",
    "# csv 형태로 저장하기\n",
    "naver_blog.to_csv(fc_name,encoding=\"utf-8-sig\",index=False)\n",
    "print(\"csv 파일 저장 경로: %s\" %fc_name) \n",
    "\n",
    "# 엑셀 형태로 저장하기\n",
    "naver_blog.to_excel(fx_name , index=False , encoding=\"UTF-8\" , engine='openpyxl')\n",
    "print(\"xls 파일 저장 경로: %s\" %fx_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>rdate</th>\n",
       "      <th>nick</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿번호</td>\n",
       "      <td>제목</td>\n",
       "      <td>내용</td>\n",
       "      <td>작성일자</td>\n",
       "      <td>블로그닉네임</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>전문가에게 길을 묻다. 빅데이터 전문가편 서진수 대표</td>\n",
       "      <td>빅데이터 전문가편을 진행하였습니다. 각종 티비 프로그램과 인공지능과 관련된... 등...</td>\n",
       "      <td>2022.08.06.</td>\n",
       "      <td>뉴턴의과학실&amp;뷰사이언스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>마소캠퍼스 빅데이터 분석 오픈 세미나!(서진수 대표님) 151030</td>\n",
       "      <td>진행한 빅데이터 분석 오픈 세미나 강연 후기입니다 진행은 서진수 대표님이... 하락...</td>\n",
       "      <td>2015.10.31.</td>\n",
       "      <td>어쩐지 오늘은</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>빅데이터 전문가 서진수 대표의 트랜드 분석 강의</td>\n",
       "      <td>빅데이터 전문가 서진수 대표님. 빅데이터 강의는 분야를 막론하고 누구든... 미래 ...</td>\n",
       "      <td>2017.03.07.</td>\n",
       "      <td>카루의 프리랜서 라이프</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>소셜포럼] 서진수 대표, 변화의 흐름을 이끄는 빅데이터...</td>\n",
       "      <td>창의와 융합의 신(新) 물결 ‘4차 산업혁명’ 변화의 흐름을 이끄는 빅데이터 전문가...</td>\n",
       "      <td>2017.08.24.</td>\n",
       "      <td>위클리피플 [명사와의 만남] _신지식인 소셜포럼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>방법, 빅데이터 관리가 가장 기본 &lt;(주)컨시어지소프트 서진수...</td>\n",
       "      <td>된 빅데이터 기술 활용법 알린다” ㈜컨시어지소프트, ㈜데이터앤피플 서진수 대표 4차...</td>\n",
       "      <td>2017.09.25.</td>\n",
       "      <td>월간 인터뷰 (Interview)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>빅데이터 활용으로 4차산업시대를 준비하자_서진수대표 특강...</td>\n",
       "      <td>스몰데이터만으로도 충분히 고객관리가 가능합니다. ^^ 그렇게 지난 날의 관심과 열정...</td>\n",
       "      <td>2017.02.28.</td>\n",
       "      <td>위드앤교육컨설팅_퍼실리테이션 전문교육</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>빅데이터 전문가 서진수 강사님의 빅데이터 활용과 4차산업에...</td>\n",
       "      <td>서진수 강사님의 빅데이터 관련 강의를 들으러 강남을 다녀왔드랬죠!! 빅데이터 전문가...</td>\n",
       "      <td>2017.02.27.</td>\n",
       "      <td>한결다온교육연구소</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>빅데이터 분석, 웹크롤링 강남 아이티윌과 서진수 강사님의 특강</td>\n",
       "      <td>오늘은 강남 아이티윌과 서진수 강사님의 빅데이터분석을 위한 R의 활용방안과 텍스트 ...</td>\n",
       "      <td>2017.08.08.</td>\n",
       "      <td>우수훈련기관 아이티윌</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[모임소개] KBS \"명견만리\" 서진수 직강 '빅데이터 전문가...</td>\n",
       "      <td>(8) 2018.04.22 윈도우10 포스트잇 Sticky Notes 스티커 메모 ...</td>\n",
       "      <td>2018.04.11.</td>\n",
       "      <td>푸우시로의 블로그</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>서진수 강사님의 빅데이터-R을 활용한 텍스트 마이닝 교육</td>\n",
       "      <td>서진수 강사님은 빅데이터 전문가로써 방송에도 몇차례 출연하시면서 빅데이터에 관련된 ...</td>\n",
       "      <td>2017.07.25.</td>\n",
       "      <td>IT취업 나도 할 수 있다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     no                                  title  \\\n",
       "0   ﻿번호                                     제목   \n",
       "1     1          전문가에게 길을 묻다. 빅데이터 전문가편 서진수 대표   \n",
       "2     2  마소캠퍼스 빅데이터 분석 오픈 세미나!(서진수 대표님) 151030   \n",
       "3     3             빅데이터 전문가 서진수 대표의 트랜드 분석 강의   \n",
       "4     4      소셜포럼] 서진수 대표, 변화의 흐름을 이끄는 빅데이터...   \n",
       "5     5  방법, 빅데이터 관리가 가장 기본 <(주)컨시어지소프트 서진수...   \n",
       "6     6     빅데이터 활용으로 4차산업시대를 준비하자_서진수대표 특강...   \n",
       "7     7    빅데이터 전문가 서진수 강사님의 빅데이터 활용과 4차산업에...   \n",
       "8     8     빅데이터 분석, 웹크롤링 강남 아이티윌과 서진수 강사님의 특강   \n",
       "9     9  [모임소개] KBS \"명견만리\" 서진수 직강 '빅데이터 전문가...   \n",
       "10   10        서진수 강사님의 빅데이터-R을 활용한 텍스트 마이닝 교육   \n",
       "\n",
       "                                              content        rdate  \\\n",
       "0                                                  내용         작성일자   \n",
       "1   빅데이터 전문가편을 진행하였습니다. 각종 티비 프로그램과 인공지능과 관련된... 등...  2022.08.06.   \n",
       "2   진행한 빅데이터 분석 오픈 세미나 강연 후기입니다 진행은 서진수 대표님이... 하락...  2015.10.31.   \n",
       "3   빅데이터 전문가 서진수 대표님. 빅데이터 강의는 분야를 막론하고 누구든... 미래 ...  2017.03.07.   \n",
       "4   창의와 융합의 신(新) 물결 ‘4차 산업혁명’ 변화의 흐름을 이끄는 빅데이터 전문가...  2017.08.24.   \n",
       "5   된 빅데이터 기술 활용법 알린다” ㈜컨시어지소프트, ㈜데이터앤피플 서진수 대표 4차...  2017.09.25.   \n",
       "6   스몰데이터만으로도 충분히 고객관리가 가능합니다. ^^ 그렇게 지난 날의 관심과 열정...  2017.02.28.   \n",
       "7   서진수 강사님의 빅데이터 관련 강의를 들으러 강남을 다녀왔드랬죠!! 빅데이터 전문가...  2017.02.27.   \n",
       "8   오늘은 강남 아이티윌과 서진수 강사님의 빅데이터분석을 위한 R의 활용방안과 텍스트 ...  2017.08.08.   \n",
       "9   (8) 2018.04.22 윈도우10 포스트잇 Sticky Notes 스티커 메모 ...  2018.04.11.   \n",
       "10  서진수 강사님은 빅데이터 전문가로써 방송에도 몇차례 출연하시면서 빅데이터에 관련된 ...  2017.07.25.   \n",
       "\n",
       "                           nick  \n",
       "0                        블로그닉네임  \n",
       "1                  뉴턴의과학실&뷰사이언스  \n",
       "2                       어쩐지 오늘은  \n",
       "3                  카루의 프리랜서 라이프  \n",
       "4    위클리피플 [명사와의 만남] _신지식인 소셜포럼  \n",
       "5            월간 인터뷰 (Interview)  \n",
       "6          위드앤교육컨설팅_퍼실리테이션 전문교육  \n",
       "7                     한결다온교육연구소  \n",
       "8                   우수훈련기관 아이티윌  \n",
       "9                     푸우시로의 블로그  \n",
       "10              IT취업 나도 할 수 있다.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################################################################################################\n",
    "# My SQL DB 관련 작업\n",
    "###################################################################################################################\n",
    "# 아래의 작업을 하기 전에 먼저 MySQL DB에서 아래의 작업을 수행해주세요\n",
    "#[Step 1. 윈도의 명령 프롬프트 창을 실행하여  Mysql 에 접속하기 ]\n",
    "#C:\\WINDOWS\\system32>mysql -u root -p\n",
    "#Enter password: *****\n",
    "#\n",
    "#[Step 2.  수집한 데이터를 저장할 데이터 베이스 생성하기 ]\n",
    "#mysql> CREATE DATABASE crawl_data DEFAULT CHARACTER SET utf8;\n",
    "#\n",
    "#[Step 3. 수집한 데이터를 관리할 계정 생성하기]\n",
    "#mysql> CREATE USER cuser IDENTIFIED BY 'cuser!@#';\n",
    "#\n",
    "#[Step 4. 생성한 계정에 권한 설정하기 ]\n",
    "#mysql> GRANT ALL ON crawl_data.* TO cuser;\n",
    "####################################################################################################################\n",
    "\n",
    "#Step 8. MySQL DB에 저장하기\n",
    "# 접속 정보 등록 및 커서 생성하기\n",
    "import pymysql\n",
    "conn = pymysql.connect(host='192.168.150.130', user='cuser', password='cuser!@#', \\\n",
    "                       db='crawl_data', charset='utf8')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# 테이블 생성하기\n",
    "dropsql = \"DROP TABLE IF EXISTS naver_blog\"\n",
    "cur.execute(dropsql)\n",
    "\n",
    "sql = '''CREATE TABLE naver_blog (no char(4), \n",
    "         title char(50), content char(200), rdate  char(20) ,nick char(30) )\n",
    "'''\n",
    "cur.execute(sql)\n",
    "\n",
    "# csv 파일 읽어서 테이블에 데이터 입력하기\n",
    "import csv\n",
    "\n",
    "sql = \"insert into naver_blog (no, title, content, rdate , nick) values (%s, %s, %s,%s , %s)\"\n",
    "file = open(fc_name, 'r', encoding='utf-8')\n",
    "rdata = csv.reader(file)\n",
    "\n",
    "for i in rdata:\n",
    "    cur.execute(sql, (i[0], i[1], i[2] , i[3], i[4]))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "file.close( )\n",
    "\n",
    "#Step 10. 입력된 데이터 조회하기\n",
    "import pymysql\n",
    "conn = pymysql.connect(host='192.168.150.130', user='cuser', password='cuser!@#', \\\n",
    "                       db='crawl_data', charset='utf8')\n",
    "cur = conn.cursor(pymysql.cursors.DictCursor)\n",
    "\n",
    "sql = \"SELECT * FROM naver_blog\"\n",
    "cur.execute(sql)\n",
    "result = cur.fetchall()    \n",
    "\n",
    "import pandas as pd\n",
    "result2 = pd.DataFrame(result)\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
