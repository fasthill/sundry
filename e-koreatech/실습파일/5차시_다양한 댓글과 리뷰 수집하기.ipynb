{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "뉴스 기사의 댓글 정보 수집하기\n",
      "================================================================================\n",
      "1.크롤링 할 뉴스 리뷰 건수는 몇건입니까?(기본값: 20건): 10\n",
      "2.결과를 파일을 저장할 폴더명만 쓰세요(기본값:c:\\py_temp\\):\n",
      "================================================================================\n",
      "전체 검색 결과 건수 : 505 건\n",
      "실제 최종 출력 건수 : 10\n",
      "총 페이지 수: 1\n"
     ]
    }
   ],
   "source": [
    "#Step 1. 필요한 모듈과 라이브러리를 로딩합니다.\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import math\n",
    "import numpy  \n",
    "import pandas as pd  \n",
    "import os\n",
    "\n",
    "\n",
    "#Step 2. 사용자에게 검색어 키워드를 입력 받고 저장할 폴더와 파일명을 설정합니다.\n",
    "print(\"=\" *80)\n",
    "print(\"뉴스 기사의 댓글 정보 수집하기\")\n",
    "print(\"=\" *80)\n",
    "\n",
    "query_txt = '뉴스기사댓글'\n",
    "query_url = 'https://news.naver.com/main/read.nhn?mode=LSD&mid=shm&sid1=102&oid=056&aid=0010661268'\n",
    "try :\n",
    "    cnt = int(input('1.크롤링 할 뉴스 리뷰 건수는 몇건입니까?(기본값: 20건): '))\n",
    "except ValueError :\n",
    "    cnt = 20\n",
    "\n",
    "page_cnt = math.ceil(cnt / 20)\n",
    "\n",
    "f_dir = input(\"2.결과를 파일을 저장할 폴더명만 쓰세요(기본값:c:\\\\py_temp\\\\):\")\n",
    "if f_dir=='' :\n",
    "    f_dir='c:\\\\py_temp\\\\'\n",
    "    \n",
    "# 저장될 파일위치와 이름을 지정합니다\n",
    "now = time.localtime()\n",
    "s = '%04d-%02d-%02d-%02d-%02d-%02d' % (now.tm_year, now.tm_mon, now.tm_mday, \\\n",
    "                                       now.tm_hour, now.tm_min, now.tm_sec)\n",
    "\n",
    "os.makedirs(f_dir+s+'-'+query_txt)\n",
    "os.chdir(f_dir+s+'-'+query_txt)\n",
    "\n",
    "ff_name=f_dir+s+'-'+query_txt+'\\\\'+s+'-'+query_txt+'.txt'\n",
    "fc_name=f_dir+s+'-'+query_txt+'\\\\'+s+'-'+query_txt+'.csv'\n",
    "fx_name=f_dir+s+'-'+query_txt+'\\\\'+s+'-'+query_txt+'.xls'\n",
    "\n",
    "#Step 3. 크롬 드라이버를 사용해서 웹 브라우저를 실행합니다.\n",
    "s_time = time.time( )\n",
    "\n",
    "s = Service(\"c:/py_temp/chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "driver.get(query_url)\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "\n",
    "# 현재 총 리뷰 건수를 확인하여 사용자의 요청건수와 비교 후 동기화합니다\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "result= soup.find('div','media_end_head_info_variety_cmtcount _COMMENT_HIDE').get_text()\n",
    "\n",
    "print(\"=\" *80)\n",
    "search_cnt = int( result.replace(\",\",\"\"))\n",
    "\n",
    "if cnt > search_cnt :\n",
    "    cnt = search_cnt\n",
    "\n",
    "print(\"전체 검색 결과 건수 :\",search_cnt,\"건\")\n",
    "print(\"실제 최종 출력 건수 :\",cnt)\n",
    "print(\"총 페이지 수:\" , page_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 사용자가 요청한 건수가 많을 경우 리뷰 더보기 버튼을 클릭합니다\n",
    "# 최초 10건 수집후 댓글 더보기 버튼 클릭\n",
    "# 아래 버튼을 눌러 첫 화면에 총 20건의 댓글이 나오게 만듦\n",
    "driver.find_element(By.XPATH,'//*[@id=\"cbox_module\"]/div/div[9]/a/span[1]').click()\n",
    "time.sleep(3)\n",
    "\n",
    "#Step 6. 20건 출력되어 있는 현재 페이지 리뷰와 점수 등 내용 수집\n",
    "no2= []             # 리뷰 번호 \n",
    "writer_id2=[]       # 리뷰 작성자 ID\n",
    "review2=[]          # 리뷰 내용\n",
    "write_date2=[]      # 리뷰 작성 일자\n",
    "gogam_0=[]          # 공감 횟수\n",
    "gogam_1=[]          # 비공감 횟수\n",
    "count = 0\n",
    "\n",
    "for a in range(1,page_cnt+1) :\n",
    "    \n",
    "    if a == page_cnt :\n",
    "          break\n",
    "    else :\n",
    "        driver.find_element(By.XPATH,'//*[@id=\"cbox_module\"]/div/div[9]/a').click() \n",
    "        time.sleep(3)\n",
    "        print(\"%s페이지 이동 완료=================================================\" %a)\n",
    "        time.sleep(random.randrange(1,3))  # 3-8 초 사이에 랜덤으로 시간 선택\n",
    "\n",
    "print('이제 리뷰 정보를 수집합니다. 잠시만 기다려 주세요~~~~~~~~')\n",
    "\n",
    "#txt 파일에 저장하기 위해 파일 open하기\n",
    "f = open(ff_name, 'a',encoding='UTF-8')\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "slist = soup.find('ul', 'u_cbox_list').find_all('li')\n",
    "\n",
    "for li in slist:\n",
    "    count += 1\n",
    "    print(\"\\n\")\n",
    "    print(\"총 %s건 중 %s번째 댓글 수집 중입니다 ==================\" %(cnt,count))\n",
    "    \n",
    "    # 리뷰 번호 저장\n",
    "    no2.append(count)\n",
    "    \n",
    "    # 리뷰 작성자 ID 저장\n",
    "    writer_id = li.find('span','u_cbox_nick').get_text()\n",
    "    print(\"1.작성자ID:\", writer_id)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"총 %s 건 중 %s 번째 리뷰 데이터를 수집합니다==============\" %(cnt,count) + \"\\n\")\n",
    "    f.write(\"1.작성자ID:\"+writer_id + \"\\n\")\n",
    "    writer_id2.append(writer_id)\n",
    "    \n",
    "    #리뷰 내용 저장\n",
    "    try :\n",
    "        review = li.find('span', class_='u_cbox_contents').get_text()\n",
    "    except AttributeError :\n",
    "        review='작성자에 의해 삭제된 댓글입니다'\n",
    "        print(\"2.리뷰 :\",review)\n",
    "    else :\n",
    "        print(\"2.리뷰:\",review)\n",
    "    f.write(\"2.리뷰:\" + review + \"\\n\")\n",
    "    review2.append(review)\n",
    "\n",
    "    # 리뷰 작성일자 저장\n",
    "    write_date = li.find('span',class_='u_cbox_date').get_text()\n",
    "    print('3.작성일자:',write_date)\n",
    "    f.write(\"3.작성일자:\" + write_date + \"\\n\")\n",
    "    write_date2.append(write_date)\n",
    "\n",
    "    # 공감 / 비공감 횟수 저장\n",
    "    gogam = li.find('div', class_='u_cbox_recomm_set').find_all('em')\n",
    "    \n",
    "    try :\n",
    "        g_gogam = gogam[0].text\n",
    "        print('4.공감:',g_gogam)\n",
    "    except IndexError :\n",
    "        g_gogam = '0'\n",
    "        print('4.공감 :',g_gogam)\n",
    "    f.write(\"4.공감:\" + g_gogam + \"\\n\")\n",
    "    gogam_0.append(g_gogam)\n",
    "\n",
    "    try :\n",
    "        b_gogam = gogam[1].text\n",
    "        print('5.비공감:',b_gogam) \n",
    "    except IndexError :\n",
    "        b_gogam = '0'\n",
    "        print('5.비공감 :',b_gogam)\n",
    "    f.write(\"5.비공감:\" + b_gogam + \"\\n\")\n",
    "    gogam_1.append(b_gogam)\n",
    "      \n",
    "    time.sleep(0.2)      \n",
    "\n",
    "    if count == cnt :\n",
    "         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 결과를 표(데이터 프레임) 형태로 만들기\n",
    "news_review = pd.DataFrame()\n",
    "news_review['번호'] = no2\n",
    "news_review['작성자ID'] = pd.Series(writer_id2)\n",
    "news_review['리뷰내용'] = pd.Series(review2)\n",
    "news_review['작성일자'] = pd.Series(write_date2)\n",
    "news_review['공감횟수'] = pd.Series(gogam_0)\n",
    "news_review['비공감횟수'] = pd.Series(gogam_0)\n",
    "\n",
    "# csv 형태로 저장하기\n",
    "news_review.to_csv(fc_name,encoding=\"utf-8-sig\",index=False)\n",
    "print(\" csv 파일 저장 경로: %s\" %fc_name) \n",
    "\n",
    "# 엑셀 형태로 저장하기\n",
    "news_review.to_excel(fx_name , index=False , encoding=\"UTF-8\" , engine='openpyxl')\n",
    "print(\" xls 파일 저장 경로: %s\" %fx_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
